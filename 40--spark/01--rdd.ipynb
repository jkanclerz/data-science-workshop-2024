{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/jkanclerz/data-science-workshop-2024/blob/main/40--spark/01--rdd.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.0.0)\r\n",
      "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\r\n"
     ]
    }
   ],
   "source": [
    "!apt-get install openjdk-17-jdk-headless -qq > /dev/null\n",
    "!wget https://dlcdn.apache.org/spark/spark-3.5.4/spark-3.5.4-bin-hadoop3.tgz -O spark-3.5.4-bin-hadoop3.tgz\n",
    "!tar xf spark-3.5.4-bin-hadoop3.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-17-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.5.4-bin-hadoop3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:55:33 WARN Utils: Your hostname, Jakubs-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.8.5 instead (on interface en0)\n",
      "23/01/20 20:55:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/20 20:55:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"DDD\")\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.8.5:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test it</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10c8843d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resilient Distributed Dataset or RDD\n",
    "\n",
    "An RDD is a distributed collection of elements. All work in Spark is expressed as either creating new RDDs, transforming existing RDDs, or calling actions on RDDs to compute a result. Spark automatically distributes the data contained in RDDs across your cluster and parallelizes the operations you perform on them.\n",
    "\n",
    "https://spark.apache.org/docs/latest/rdd-programming-guide.html#resilient-distributed-datasets-rdds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating and RDD using parallelize\n",
    "Another way of creating an RDD is to parallelize an already existing list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = ((a, a*a) for a in range(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sc.parallelize(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 1),\n",
       " (2, 4),\n",
       " (3, 9),\n",
       " (4, 16),\n",
       " (5, 25),\n",
       " (6, 36),\n",
       " (7, 49),\n",
       " (8, 64),\n",
       " (9, 81)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a RDD from a file\n",
    "The most common way of creating an RDD is to load it from a file. Notice that Spark's textFile can handle compressed files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-01-20 20:57:05--  https://wolnelektury.pl/media/book/txt/krzyzacy-tom-pierwszy.txt\n",
      "Resolving wolnelektury.pl (wolnelektury.pl)... 51.83.143.148\n",
      "Connecting to wolnelektury.pl (wolnelektury.pl)|51.83.143.148|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 740368 (723K) [text/plain]\n",
      "Saving to: ‘var/krzyzacy-1.txt’\n",
      "\n",
      "var/krzyzacy-1.txt  100%[===================>] 723,02K  --.-KB/s    in 0,08s   \n",
      "\n",
      "2023-01-20 20:57:05 (8,31 MB/s) - ‘var/krzyzacy-1.txt’ saved [740368/740368]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p var\n",
    "!wget https://wolnelektury.pl/media/book/txt/krzyzacy-tom-pierwszy.txt -O var/krzyzacy-1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile('var/krzyzacy-1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kDF = spark.read.text('var/krzyzacy-1.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = spark.createDataFrame([(\"Krakow\", \"1\", {\"foo\": \"boo\"}), (\"Warszawa\", \"2\", {})], ['City', \"digit\", \"attr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+------------+\n",
      "|    City|digit|        attr|\n",
      "+--------+-----+------------+\n",
      "|  Krakow|    1|{foo -> boo}|\n",
      "|Warszawa|    2|          {}|\n",
      "+--------+-----+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "!echo '{\"city\":\"Lublin\",\"digit\":5,\"attr\":{\"foo\":\"zoo\"}}' > cities.list\n",
    "!echo '{\"city\":\"Bielski\",\"digit\":2,\"attr\":{\"sigma\":\"gamma\"}}' >> cities.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"city\":\"Lublin\",\"digit\":5,\"attr\":{\"foo\":\"zoo\"}}\r\n",
      "{\"city\":\"Bielski\",\"digit\":2,\"attr\":{\"sigma\":\"gamma\"}}\r\n"
     ]
    }
   ],
   "source": [
    "cat cities.list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = (spark.read\n",
    "     .option('dropFieldIfAllNull', True)\n",
    "     .option(\"primitivesAsString\", True)\n",
    "     .json(\"cities.list\")\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- attr: struct (nullable = true)\n",
      " |    |-- foo: string (nullable = true)\n",
      " |    |-- sigma: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- digit: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplicate = F.udf(lambda x: int(x)*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = c.withColumn(\"multipled\", multiplicate(F.col(\"digit\")))\n",
    "c = c.withColumnRenamed('digit', 'number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|foo|  city|\n",
      "+---+------+\n",
      "|zoo|Lublin|\n",
      "+---+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "c.select(['attr.foo','city']).where('(attr.foo is not null)').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = spark.createDataFrame([\n",
    "    ('nice one', ['foo', 'moo', 'boo', 'zoo']),\n",
    "    ('bad one', ['foo', 'moo',])\n",
    "],\n",
    "['title', 'tags']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|   title|                tags|\n",
      "+--------+--------------------+\n",
      "|nice one|[foo, moo, boo, zoo]|\n",
      "| bad one|          [foo, moo]|\n",
      "+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- title: string (nullable = true)\n",
      " |-- tags: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|   title|col|\n",
      "+--------+---+\n",
      "|nice one|foo|\n",
      "|nice one|moo|\n",
      "|nice one|boo|\n",
      "|nice one|zoo|\n",
      "| bad one|foo|\n",
      "| bad one|moo|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T.select('title', F.explode('tags')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+\n",
      "|   title|col|\n",
      "+--------+---+\n",
      "|nice one|foo|\n",
      "|nice one|moo|\n",
      "|nice one|boo|\n",
      "|nice one|zoo|\n",
      "| bad one|foo|\n",
      "| bad one|moo|\n",
      "+--------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T.select('title', F.explode_outer('tags')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|col|\n",
      "+---+\n",
      "|  1|\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "| 12|\n",
      "| 13|\n",
      "| 14|\n",
      "| 15|\n",
      "| 16|\n",
      "| 17|\n",
      "| 18|\n",
      "| 19|\n",
      "| 20|\n",
      "+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select explode(sequence(1,1000))\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------------+\n",
      "|dayofweek(now())|next_day(now(), Mon)|\n",
      "+----------------+--------------------+\n",
      "|               6|          2023-01-23|\n",
      "+----------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql('''\n",
    "select dayofweek(now()), next_day(now(), \"Mon\")\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|SPARK_PARTITION_ID()|           version()|\n",
      "+--------------------+--------------------+\n",
      "|                   0|3.3.1 fbbcf9434ac...|\n",
      "|                   0|3.3.1 fbbcf9434ac...|\n",
      "+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "T.select(F.spark_partition_id(), F.expr('version()')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = kDF.withColumn(\"NewCol\", F.col(\"value\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k.drop(\"value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              NewCol|\n",
      "+--------------------+\n",
      "|  Henryk Sienkiewicz|\n",
      "|                    |\n",
      "|            Krzyżacy|\n",
      "|               Tom I|\n",
      "|                    |\n",
      "|ISBN 978-83-288-2...|\n",
      "|                    |\n",
      "|                    |\n",
      "|                    |\n",
      "|                    |\n",
      "|   Rozdział pierwszy|\n",
      "|                    |\n",
      "|W Tyńcu, w gospod...|\n",
      "|                    |\n",
      "|Tuż przy nim za s...|\n",
      "|                    |\n",
      "|Gospodarz Niemiec...|\n",
      "|                    |\n",
      "|Jeszcze ciekawiej...|\n",
      "|                    |\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = k.withColumns({'starts_with1': F.col(\"NewCol\"), 'x': F.col(\"NewCol\"), 'y': F.col('NewCol').startswith('A')})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+----+\n",
      "|              NewCol|        starts_with1|                   x|   y|\n",
      "+--------------------+--------------------+--------------------+----+\n",
      "|  A Zbyszko odrzekł:|  A Zbyszko odrzekł:|  A Zbyszko odrzekł:|true|\n",
      "|A wtem przez drzw...|A wtem przez drzw...|A wtem przez drzw...|true|\n",
      "|A Zbyszkowi zaświ...|A Zbyszkowi zaświ...|A Zbyszkowi zaświ...|true|\n",
      "|A przetowłosa Dan...|A przetowłosa Dan...|A przetowłosa Dan...|true|\n",
      "|  A Zbyszko odrzekł:|  A Zbyszko odrzekł:|  A Zbyszko odrzekł:|true|\n",
      "|  A potem do Danusi:|  A potem do Danusi:|  A potem do Danusi:|true|\n",
      "|A zakonnicy nie o...|A zakonnicy nie o...|A zakonnicy nie o...|true|\n",
      "|A Maćko śmiał się...|A Maćko śmiał się...|A Maćko śmiał się...|true|\n",
      "|A potem, wyciągną...|A potem, wyciągną...|A potem, wyciągną...|true|\n",
      "|Ale jej nie zbudz...|Ale jej nie zbudz...|Ale jej nie zbudz...|true|\n",
      "|A oni rzeczywiści...|A oni rzeczywiści...|A oni rzeczywiści...|true|\n",
      "|A Zbyszkowi rozja...|A Zbyszkowi rozja...|A Zbyszkowi rozja...|true|\n",
      "|A brat Hidulf poc...|A brat Hidulf poc...|A brat Hidulf poc...|true|\n",
      "|A brat Hidulf rzekł:|A brat Hidulf rzekł:|A brat Hidulf rzekł:|true|\n",
      "|A tak samo pobożn...|A tak samo pobożn...|A tak samo pobożn...|true|\n",
      "|A ja, grzeszny Zb...|A ja, grzeszny Zb...|A ja, grzeszny Zb...|true|\n",
      "|A opat zmarszczył...|A opat zmarszczył...|A opat zmarszczył...|true|\n",
      "|A Maćko, który mi...|A Maćko, który mi...|A Maćko, który mi...|true|\n",
      "|A tamten zdumiał ...|A tamten zdumiał ...|A tamten zdumiał ...|true|\n",
      "|Ale tymczasem nad...|Ale tymczasem nad...|Ale tymczasem nad...|true|\n",
      "+--------------------+--------------------+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "k.filter(k['y'] == True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "var/krzyzacy-1.txt MapPartitionsRDD[4] at textFile at NativeMethodAccessorImpl.java:0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7607"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Henryk Sienkiewicz',\n",
       " '',\n",
       " 'Krzyżacy',\n",
       " 'Tom I',\n",
       " '',\n",
       " 'ISBN 978-83-288-2813-1',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = file.filter(lambda x: x != '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Henryk Sienkiewicz',\n",
       " 'Krzyżacy',\n",
       " 'Tom I',\n",
       " 'ISBN 978-83-288-2813-1',\n",
       " 'Rozdział pierwszy',\n",
       " 'W Tyńcu, w gospodzie „Pod Lutym Turem”, należącej do opactwa, siedziało kilku ludzi, słuchając opowiadania wojaka bywalca, który z dalekich stron przybywszy, prawił im o przygodach, jakich na wojnie i w czasie podróży doznał. Człek był brodaty, w sile wieku, pleczysty, prawie ogromny, ale wychudły; włosy nosił ujęte w pątlik, czyli w siatkę naszywaną paciorkami; na sobie miał skórzany kubrak z pręgami wyciśniętymi przez pancerz, na nim pas, cały z miedzianych klamr; za pasem nóż w rogowej pochwie, przy boku zaś krótki kord podróżny.',\n",
       " 'Tuż przy nim za stołem siedział młodzieńczyk o długich włosach i wesołym spojrzeniu, widocznie jego towarzysz lub może giermek, bo przybrany także po podróżnemu, w taki sam powyciskany od zbroicy skórzany kubrak. Resztę towarzystwa stanowiło dwóch ziemian z okolic Krakowa i trzech mieszczan w czerwonych składanych czapkach, których cienkie końce zwieszały się im z boku aż na łokcie.',\n",
       " 'Gospodarz Niemiec, w płowym kapturze z kołnierzem wycinanym w zęby, lał im z konwi sytne piwo do glinianych stągiewek i nasłuchiwał ciekawie przygód wojennych.',\n",
       " 'Jeszcze ciekawiej jednak słuchali mieszczanie. W owych czasach nienawiść, jaka dzieliła za czasów Łokietkowych miasto od rycerskiego ziemiaństwa, znacznie już była przygasła, mieszczaństwo zaś nosiło głowy górniej niż w wiekach późniejszych. Jeszcze ceniono ich gotowość ad concessionem pecuniarum; dlatego też nieraz zdarzało się widzieć w gospodach kupców pijących za pan brat ze szlachtą. Widziano ich nawet chętnie, bo jako ludzie, u których o gotowy grosz łatwiej, płacili zwykle za herbowych.',\n",
       " 'Tak więc siedzieli teraz i rozmawiali, mrugając od czasu do czasu na gospodarza, aby napełniał stągiewki.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = filtered \\\n",
    "    .flatMap(lambda line: line.split(\" \")) \\\n",
    "    .map(lambda word: (word, 1)) \\\n",
    "    .reduceByKey(lambda acc, item: acc + item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 24),\n",
       " ('(bo', 1),\n",
       " ('(http://creativecommons.org/licenses/by-sa/3.0/).', 1),\n",
       " ('(http://wolnelektury.pl).', 1),\n",
       " ('(precz', 1)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.takeOrdered(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('—', 4339), ('i', 3906), ('się', 2486), ('nie', 2024), ('w', 2017)]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.takeOrdered(5, key=lambda x: -x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-12-11 07:13:17--  https://wolnelektury.pl/media/book/txt/krzyzacy-tom-drugi.txt\n",
      "Resolving wolnelektury.pl (wolnelektury.pl)... 51.83.143.148\n",
      "Connecting to wolnelektury.pl (wolnelektury.pl)|51.83.143.148|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 840889 (821K) [text/plain]\n",
      "Saving to: ‘var/krzyzacy-2.txt’\n",
      "\n",
      "var/krzyzacy-2.txt  100%[===================>] 821.18K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2021-12-11 07:13:17 (8.38 MB/s) - ‘var/krzyzacy-2.txt’ saved [840889/840889]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p var\n",
    "!wget https://wolnelektury.pl/media/book/txt/krzyzacy-tom-drugi.txt -O var/krzyzacy-2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = sc.textFile('var/krzyzacy*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15477"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = spark.createDataFrame([(a,) for a in range(1,100,1)], ['col'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "|col|\n",
      "+---+\n",
      "|  9|\n",
      "| 35|\n",
      "| 72|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "A.sample(0.05, seed=17).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a1af0ee75eeea9e2e1ee996c87e7a2b11a0bebd85af04bb136d915cefc0abce"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
